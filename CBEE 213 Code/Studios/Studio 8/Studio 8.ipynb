{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANOVA\n",
    "\n",
    "Last week we did a deep dive into Analysis of Variance.  After this hands-on exercise we have a better understanding of the underlying process which allows us to draw conclusions about the liklihood that various samples came from different populations.\n",
    "\n",
    "Today we'll explore a multi-factor data set. We'll start out with some basic exploratory data analysis, then we'll apply our knowledge of t-tests and one-way ANOVA to each of the factors.  Finally we'll acount for both factors with a two-way ANOVA and apply a post-hoc test to determine which of our factors are significant.\n",
    "\n",
    "The data set contains some plant growth data.  Plant height was measured for several groups. Both watering schedule and sunlight intensity were varied in the experiment.  The goal is the see if watering frequency and sunlight intensity affect the final height of the plant.\n",
    "\n",
    "Lets get some libraries!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "from scipy import stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the data**\n",
    "\n",
    "Put the `plants.csv` file into your current directory and load it into a pandas DataFrame. If you forget the method, either do a search for it or use a previous studio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Could not convert string 'dailydailydailydaily' to numeric",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 79\u001b[39m\n\u001b[32m     76\u001b[39m sorted_plants_data = data_sorter(plants_data)\n\u001b[32m     78\u001b[39m \u001b[38;5;66;03m# Analyzes the data that was sorted \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m analyzed_plants_data = \u001b[43mdata_analyzer\u001b[49m\u001b[43m(\u001b[49m\u001b[43msorted_plants_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[38;5;28mprint\u001b[39m(plants_data, sorted_plants_data, analyzed_plants_data)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 51\u001b[39m, in \u001b[36mdata_analyzer\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m     46\u001b[39m key = (water, sun, height)\n\u001b[32m     48\u001b[39m df = pd.DataFrame(rows)\n\u001b[32m     50\u001b[39m stats = {\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mwater mean\u001b[39m\u001b[33m'\u001b[39m : \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mwater\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m,\n\u001b[32m     52\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mwater stdev\u001b[39m\u001b[33m'\u001b[39m : df[\u001b[33m'\u001b[39m\u001b[33mwater\u001b[39m\u001b[33m'\u001b[39m].std(skipna=\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[32m     53\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mwater median\u001b[39m\u001b[33m'\u001b[39m : df[\u001b[33m'\u001b[39m\u001b[33mwater\u001b[39m\u001b[33m'\u001b[39m].median(skipna=\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[32m     54\u001b[39m     \u001b[33m'\u001b[39m\u001b[33msun mean\u001b[39m\u001b[33m'\u001b[39m : df[\u001b[33m'\u001b[39m\u001b[33msun\u001b[39m\u001b[33m'\u001b[39m].mean(skipna=\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[32m     55\u001b[39m     \u001b[33m'\u001b[39m\u001b[33msun stdev\u001b[39m\u001b[33m'\u001b[39m : df[\u001b[33m'\u001b[39m\u001b[33msun\u001b[39m\u001b[33m'\u001b[39m].std(skipna=\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[32m     56\u001b[39m     \u001b[33m'\u001b[39m\u001b[33msun median\u001b[39m\u001b[33m'\u001b[39m : df[\u001b[33m'\u001b[39m\u001b[33msun\u001b[39m\u001b[33m'\u001b[39m].median(skipna=\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[32m     57\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mheight mean\u001b[39m\u001b[33m'\u001b[39m : df[\u001b[33m'\u001b[39m\u001b[33mheight\u001b[39m\u001b[33m'\u001b[39m].mean(skipna=\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[32m     58\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mheight stdev\u001b[39m\u001b[33m'\u001b[39m : df[\u001b[33m'\u001b[39m\u001b[33mheight\u001b[39m\u001b[33m'\u001b[39m].std(skipna=\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[32m     59\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mheight median\u001b[39m\u001b[33m'\u001b[39m : df[\u001b[33m'\u001b[39m\u001b[33mheight\u001b[39m\u001b[33m'\u001b[39m].median(skipna=\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[32m     60\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mSample Size\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(df)\n\u001b[32m     61\u001b[39m }\n\u001b[32m     63\u001b[39m stats = {k: \u001b[38;5;28mfloat\u001b[39m(v) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, np.float64) \u001b[38;5;28;01melse\u001b[39;00m v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m stats.items()}\n\u001b[32m     65\u001b[39m analysis_results[key] = stats\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\treyc\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\series.py:6549\u001b[39m, in \u001b[36mSeries.mean\u001b[39m\u001b[34m(self, axis, skipna, numeric_only, **kwargs)\u001b[39m\n\u001b[32m   6541\u001b[39m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m, ndim=\u001b[32m1\u001b[39m))\n\u001b[32m   6542\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmean\u001b[39m(\n\u001b[32m   6543\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   6547\u001b[39m     **kwargs,\n\u001b[32m   6548\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m6549\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNDFrame\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\treyc\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py:12420\u001b[39m, in \u001b[36mNDFrame.mean\u001b[39m\u001b[34m(self, axis, skipna, numeric_only, **kwargs)\u001b[39m\n\u001b[32m  12413\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmean\u001b[39m(\n\u001b[32m  12414\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m  12415\u001b[39m     axis: Axis | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[32m0\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m  12418\u001b[39m     **kwargs,\n\u001b[32m  12419\u001b[39m ) -> Series | \u001b[38;5;28mfloat\u001b[39m:\n\u001b[32m> \u001b[39m\u001b[32m12420\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m  12421\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnanops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnanmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m  12422\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\treyc\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py:12377\u001b[39m, in \u001b[36mNDFrame._stat_function\u001b[39m\u001b[34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[39m\n\u001b[32m  12373\u001b[39m nv.validate_func(name, (), kwargs)\n\u001b[32m  12375\u001b[39m validate_bool_kwarg(skipna, \u001b[33m\"\u001b[39m\u001b[33mskipna\u001b[39m\u001b[33m\"\u001b[39m, none_allowed=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m> \u001b[39m\u001b[32m12377\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m  12378\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnumeric_only\u001b[49m\n\u001b[32m  12379\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\treyc\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\series.py:6457\u001b[39m, in \u001b[36mSeries._reduce\u001b[39m\u001b[34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[39m\n\u001b[32m   6452\u001b[39m     \u001b[38;5;66;03m# GH#47500 - change to TypeError to match other methods\u001b[39;00m\n\u001b[32m   6453\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m   6454\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not allow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumeric_only\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   6455\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mwith non-numeric dtypes.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   6456\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m6457\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelegate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\treyc\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\nanops.py:147\u001b[39m, in \u001b[36mbottleneck_switch.__call__.<locals>.f\u001b[39m\u001b[34m(values, axis, skipna, **kwds)\u001b[39m\n\u001b[32m    145\u001b[39m         result = alt(values, axis=axis, skipna=skipna, **kwds)\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     result = \u001b[43malt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\treyc\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\nanops.py:404\u001b[39m, in \u001b[36m_datetimelike_compat.<locals>.new_func\u001b[39m\u001b[34m(values, axis, skipna, mask, **kwargs)\u001b[39m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    402\u001b[39m     mask = isna(values)\n\u001b[32m--> \u001b[39m\u001b[32m404\u001b[39m result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[32m    407\u001b[39m     result = _wrap_results(result, orig_values.dtype, fill_value=iNaT)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\treyc\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\nanops.py:720\u001b[39m, in \u001b[36mnanmean\u001b[39m\u001b[34m(values, axis, skipna, mask)\u001b[39m\n\u001b[32m    718\u001b[39m count = _get_counts(values.shape, mask, axis, dtype=dtype_count)\n\u001b[32m    719\u001b[39m the_sum = values.sum(axis, dtype=dtype_sum)\n\u001b[32m--> \u001b[39m\u001b[32m720\u001b[39m the_sum = \u001b[43m_ensure_numeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthe_sum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    722\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[33m\"\u001b[39m\u001b[33mndim\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    723\u001b[39m     count = cast(np.ndarray, count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\treyc\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\nanops.py:1701\u001b[39m, in \u001b[36m_ensure_numeric\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m   1698\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_float(x) \u001b[38;5;129;01mor\u001b[39;00m is_integer(x) \u001b[38;5;129;01mor\u001b[39;00m is_complex(x)):\n\u001b[32m   1699\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m   1700\u001b[39m         \u001b[38;5;66;03m# GH#44008, GH#36703 avoid casting e.g. strings to numeric\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1701\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not convert string \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m to numeric\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1702\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1703\u001b[39m         x = \u001b[38;5;28mfloat\u001b[39m(x)\n",
      "\u001b[31mTypeError\u001b[39m: Could not convert string 'dailydailydailydaily' to numeric"
     ]
    }
   ],
   "source": [
    "def path_finder(file_name):\n",
    "    \n",
    "    directory = os.path.dirname('__file__')\n",
    "    file_directory = os.path.join(directory, file_name)\n",
    "       \n",
    "    file_path = file_directory\n",
    "    \n",
    "    try:\n",
    "        csv_read = pd.read_csv(file_path)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print('Failed to load data')\n",
    "        print(f'Error: {e}')\n",
    "        csv_read = None\n",
    "        \n",
    "    return csv_read\n",
    "\n",
    "def data_sorter(data):\n",
    "    \n",
    "    grouped_data = {}\n",
    "    \n",
    "    for _, row in data.iterrows():\n",
    "        \n",
    "        water = row['water']\n",
    "        sun = row['sun']\n",
    "        height = row['height']\n",
    "        \n",
    "        key = (water, sun, height)\n",
    "    \n",
    "        if key not in grouped_data:\n",
    "            grouped_data[key] = []\n",
    "            \n",
    "        grouped_data[key].append(row.to_dict())\n",
    "        \n",
    "    return grouped_data\n",
    "\n",
    "def data_analyzer(data):\n",
    "    \n",
    "    warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "    \n",
    "    analysis_results = {}\n",
    "    \n",
    "    for key, rows in data.items():\n",
    "        \n",
    "        water, sun, height = key\n",
    "        key = (water, sun, height)\n",
    "\n",
    "        df = pd.DataFrame(rows)\n",
    "        \n",
    "        stats = {\n",
    "            'water mean' : df['water'].mean(skipna=True),\n",
    "            'water stdev' : df['water'].std(skipna=True),\n",
    "            'water median' : df['water'].median(skipna=True),\n",
    "            'sun mean' : df['sun'].mean(skipna=True),\n",
    "            'sun stdev' : df['sun'].std(skipna=True),\n",
    "            'sun median' : df['sun'].median(skipna=True),\n",
    "            'height mean' : df['height'].mean(skipna=True),\n",
    "            'height stdev' : df['height'].std(skipna=True),\n",
    "            'height median' : df['height'].median(skipna=True),\n",
    "            'Sample Size': len(df)\n",
    "        }\n",
    "        \n",
    "        stats = {k: float(v) if isinstance(v, np.float64) else v for k, v in stats.items()}\n",
    "        \n",
    "        analysis_results[key] = stats\n",
    "        \n",
    "    return analysis_results\n",
    "\n",
    "# Name of CSV file\n",
    "file_name = 'plants.csv'\n",
    "\n",
    "# Gets the data from the CSV\n",
    "plants_data = path_finder(file_name)\n",
    "\n",
    "# Sorts the data from the CSV\n",
    "sorted_plants_data = data_sorter(plants_data)\n",
    "\n",
    "# Analyzes the data that was sorted \n",
    "analyzed_plants_data = data_analyzer(sorted_plants_data)\n",
    "\n",
    "print(plants_data, sorted_plants_data, analyzed_plants_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explore the data**\n",
    "\n",
    "Have a look at the DataFrame.  How many columns are there?  What kind of data is in each column?  How many unique values are in the categorical columns?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first few rows and info about the DataFrame\n",
    "print(plants_data.head())\n",
    "print(\"\\nDataFrame info:\")\n",
    "print(plants_data.info())\n",
    "\n",
    "# Unique values in categorical columns\n",
    "print(\"\\nUnique values in 'water':\", plants_data['water'].unique())\n",
    "print(\"Unique values in 'sun':\", plants_data['sun'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a boxplot which has plant height on the y-axis and watering schedule on the x-axis.  \n",
    "\n",
    "The Seaborn library is the natural choice (lookup the boxplot function), but feel free to use library you wish. Just remember to import the associated library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.boxplot(x='water', y='height', data=plants_data)\n",
    "plt.title('Plant Height by Watering Schedule')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a second box plot with plant height on the y-axis and sun intensity on the x-axis.  Take note of any differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.boxplot(x='sun', y='height', data=plants_data)\n",
    "plt.title('Plant Height by Sun Intensity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing daily vs weekly\n",
    "\n",
    "First we'll look at the difference between watering schedules only.  Since there are only two levels to this factor, we can split the height data into two samples.  \n",
    "\n",
    "First we'll isolate the \"daily\" data using a boolean index, then we'll grab the height values from that sample.\n",
    "\n",
    "```\n",
    "daily_idx = df[\"water\"] == \"daily\"\n",
    "daily_height = df[daily_idx][\"height\"]\n",
    "```\n",
    "\n",
    "NOTE: If 'df' doesn't work, use whichever variable you chose to load the data with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_height = plants_data[plants_data['water'] == 'daily']['height']\n",
    "weekly_height = plants_data[plants_data['water'] == 'weekly']['height']\n",
    "print(\"Daily heights:\", daily_height.values)\n",
    "print(\"Weekly heights:\", weekly_height.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create corresponding weekly height values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# done above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get our function from a couple weeks ago to do our two sample t-test, and we will compare it to the built-in method from SciPy.\n",
    "\n",
    "```\n",
    "st.ttest_ind(sample_1,sample_2)\n",
    "```\n",
    "\n",
    "Perform both tests on the two different samples. For the SciPy method, rembember to replace 'sample_1' and 'sample_2' with the variables you created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for fun, let's compare this value to a one-way ANOVA using just the two samples.\n",
    "\n",
    "```\n",
    "st.f_oneway(sample_1,sample_2)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the p-values are the same?  For two samples these methods are actually identical.  If we are doing the manual calculation it's a little easier to do the t-test, but if we wanted to do the algebra we could prove that they are actually calculating the same thing.\n",
    "\n",
    "So why do we have ANOVA?  As we saw last week we will often want to look at more than two samples.  In this case, doing multiple t-tests will increase our liklihood of Type I error.  The methods are not equivelent when there are more than two samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing sunlight intensity\n",
    "\n",
    "This factor has three levels, so we will have to perform an ANOVA to find our significance.  \n",
    "\n",
    "Just like we did for daily and weekly, isolate the data for each of the three levels (\"low\", \"med\", and \"high\") and perform a one-way ANOVA on the height.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can pass as many samples into the `f_oneway()` as needed.\n",
    "\n",
    "```\n",
    "st.f_oneway(sample_1, sample_2, sample_3)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic two-way ANOVA\n",
    "\n",
    "But what happens when we want to look at both factors?  Afterall it's reasonably to think that they could both have an effect.  \n",
    "\n",
    "In this case we need a two-way ANOVA.  We are not going to dive into the math of the two-way ANOVA, but it basically works the same as the one way.  We are ultimately comparing in-group variance to between-group variance.\n",
    "\n",
    "The syntax is a little weird.  Just go with it.\n",
    "\n",
    "```\n",
    "model = ols('height ~ C(water) + C(sun)', data=df).fit()\n",
    "sm.stats.anova_lm(model, typ=2)\n",
    "```\n",
    "\n",
    "You can google the `anova_lm` function to read about the input.  Or if you search for \"two-way ANOVA Python\" you'll find a lot of articles.  ANOVA is one of the most widely used statistical techniques so it's well documented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two-way ANOVA with factor interaction\n",
    "\n",
    "We just looked at the influence of both factors on the height, but what about the \"factor interaction\"?  What if the intense sunlight allows the plant to use more water, or if the daily watering schedule allowed the plant to more efficiently utilize the sunlight?  This would create a factor interact, where changing both of those variables together produced an outcome that was different than the effect of changing each one independently.\n",
    "\n",
    "We basically use the same cyntax as before, but we add a term for water-sun interaction like this:\n",
    "\n",
    "`model = ols('height ~ C(water) + C(sun) + C(water):C(sun)', data=df).fit()`\n",
    "`sm.stats.anova_lm(model, typ=2)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we do not get a significant p-value for the interaction, so we cannot conclude that there is likely to be an additional effect when we change the level of both factors.\n",
    "\n",
    "## Post-hoc\n",
    "\n",
    "The ANOVA we just performed told us that there was liekly to be a difference between our populations, but it did not tell us *which* populations were likely to be different.  For that we need to do a post-hoc test.\n",
    "\n",
    "We will use a basic test called *Tukey's range test* which is also often called *Tukey's HSD (honestly signficant difference) test*.\n",
    "\n",
    "In this case we're going to skip the math altogether.  Just try the analysis.\n",
    "\n",
    "`tukey = pairwise_tukeyhsd(endog=df['height'],groups=df['sun'],alpha=0.05)`       \n",
    "\n",
    "`print(tukey)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try it for the watering schedule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
