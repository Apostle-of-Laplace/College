{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis Testing\n",
    "\n",
    "A [statistical hypothesis test](https://en.wikipedia.org/wiki/Statistical_hypothesis_testing) is a method of statistical inference used to decide whether the data at hand (which are likely the result of taking a sample) sufficiently support a particular hypothesis. \n",
    "\n",
    "In simple terms we make an assumption about the underlying probability distribution of the population.  We call this the [*null hypothesis*](https://en.wikipedia.org/wiki/Null_hypothesis).  Since we are dealing with a sample and the spread of the sample mean distribution is described by the standard error, the assumption that we end up making is the value of the population mean.  \n",
    "\n",
    "Then we propose an alternative hypothesis.  The alternative hypothesis is important because it will ultimately tell us which end of our probability distribution we will look at to determine the cumulative probability, but we're getting ahead of ourselves.  At this point I will just say that the first time you learn this it feels like some circular logic, so you just have to do it a few times to see how it all fits together.\n",
    "\n",
    "Once we have constructed our hypothetical distribution we simply see where our sample mean value falls on that distribution and what the cumulative probability is of getting that particular sample (or a more extreme value).  A low probability implies that our assumption about the underlying population (null hypothesis) is probably wrong.  \n",
    "\n",
    "A [t-test](https://en.wikipedia.org/wiki/Student%27s_t-test) is performed when we don't know the population standard deviation.  We use the sample standard deviation instead.  Then we use the t-statistic instead of a z-statistic, and calculate our p-value using the t-distribution.\n",
    "\n",
    "When performing a t-test we are actually normalizing our data to fit on a t-distribution, so it doesn't feel like we are constructing a probability distribution.  But we are using the value that we assume in our null hypothesis to convert the sample into t-space, so we are in fact constructing a distribution.  \n",
    "\n",
    "Just like the confidence intervals we studied last week, this entire process rests on the central limit theorem.  We know our sample mean distribution will be normally distributed, and since we don'e actually know the standard deviation we use the t-distribution to account for the added uncertainty of using the sample standard deviation as a proxy.\n",
    "\n",
    "In todays lesson, our null hypothesis will be that our population average ($\\mu$) is equal to a particular value.  Our alternative hypothesis will be that the population average is either lower or higher than that paricular value.  We will use a slightly different test for each of these alternative hypothesis but the overall method will be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats as st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Left-Tailed Test\n",
    "\n",
    "A left-tailed test will allow us to check and see if the mean of a population is likely to be less than a hypothetical value.\n",
    "\n",
    "Let's work through a brief example to determine if the mean value of a process is equal to a hypothesised value.\n",
    "\n",
    "Suppose we work for a chemical company on the filling process.  We are testing some new equipment so we don't have a great estimate for the mean or standard deviation. Our goal is to get 500 grams of chemical into each container.  We take 10 measurements and we would like to know if our population mean is less than 500 grams.\n",
    "\n",
    "First we set up our null hypthesis.\n",
    "$$\\Large H_0: \\mu=500g$$\n",
    "\n",
    "The null hypothesis is the default assumption and the value that we use to construct our underlying populatin distribution.  If our data contradicts this assumption then we reject this default hypthesis in favor of the alternative hypothesis.  In this case the alternative hypothesis is:\n",
    "\n",
    "$$ \\Large H_a: \\mu < 500g$$\n",
    "\n",
    "Now that we have our null and alternative hypothesis, we can follow some basic steps to test and see if it is likely that our null hypothesis is correct.\n",
    "\n",
    "1. Calculate sample mean\n",
    "2. Calculate t-value using the sample mean, the standard error of the mean using sample standard deviation, and the population mean proposed by the null hypthesis.\n",
    "3. Calculate the cumulative probability up to that t-value using the correct DOF for the number of measurements in the sample.  This will tell us the likelihood of getting a result at least as extreme as our sample if the null hypthesis was true.\n",
    "4. Compare this cumulative probability to our required level of significance.\n",
    "\n",
    "Basically, the p-value is going to tell us how likely it is that the null hypothesis is true based on the sample.  \n",
    "\n",
    "For the t-statistic in step (2), we use the form which describes the sample distribution.\n",
    "\n",
    "$$\\Large t = \\frac{\\bar{x} - \\mu}{\\frac{s}{\\sqrt{n}}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### P-Value Visualization\n",
    "\n",
    "Before we begin our analysis, we'll make a quick function that will help us visualize the p-value.  We simply take the code from our exploration of cumulative probability distribution and package it in a function which takes the t-value and degree of freedom as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tcdf_plot_left(t,nu):\n",
    "    \"\"\"This function visualizes the cumulative \n",
    "    probability of the t-distribution up to a defined\n",
    "    t-value.  This is the p-value that will allow us\n",
    "    to make an inference (or not).\"\"\"\n",
    "    \n",
    "    # make the figure \n",
    "    plt.figure(figsize=(10,6))\n",
    "\n",
    "    # outcome space\n",
    "    x = np.linspace(-5,5,num=101)\n",
    "\n",
    "    # probability distribution\n",
    "    f = st.t.pdf(x,nu)\n",
    "    plt.plot(x,f)\n",
    "    \n",
    "    # shade the curve\n",
    "    plt.fill_between(x,f,color=\"C0\",alpha=0.2)\n",
    "\n",
    "    # fill in cummulative region (p-value)\n",
    "    x_sub = np.linspace(-5,t,num=101)\n",
    "    f_sub = st.t.pdf(x_sub,nu)\n",
    "    plt.fill_between(x_sub,f_sub,color=\"red\")\n",
    "\n",
    "    # format plot\n",
    "    plt.xlabel(\"Outcome\",fontsize=18)\n",
    "    plt.ylabel(\"Likelihood\")\n",
    "    plt.ylim(0,1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use our function to gain some intution about how the t-statistic impacts p-value.  In this case we are testing for values below the assumed population mean in the null hypothesis.  The p-value is the cumulative probability shown in red.  Test several values of `t`.  Looking at the t-statistic above, what could happpen to make `t` higher or lower?  Keep in mind that $\\mu$ will be a constant because we have made an assumption about it's value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = -2\n",
    "nu = 5\n",
    "\n",
    "tcdf_plot_left(t,nu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll write a short function to calculate the p-value using a left-tailed test.  This way we can easily test it one multiple samples.\n",
    "\n",
    "To calculate the sample mean we can use `x_bar = np.mean(sample)`.\n",
    "\n",
    "To calculate the sample standard deviaton we can use `np.std(sample,ddof=1)`.  This will use the unbiased estimator.  If we leave out the `ddof=1` then it will divide by *n* instead of *n-1*.  MATLAB uses the *n-1* by default.\n",
    "\n",
    "To count the number of elements in the sample list we can use the `len()` function.  This will be useful for automaticall calculating $n$ and $\\nu$.\n",
    "\n",
    "Once we have calculated the t-statistic, we can find the cumulative probability of landing on or below that value using the code `p = st.t.cdf(t,nu)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def left_tailed_t_test(sample,mu_0):\n",
    "    \"\"\"\n",
    "    This function calculates a p-value using a \n",
    "    left-tailed t-test for the population mean.  \n",
    "    \n",
    "    It takes two values as input.\n",
    "    \n",
    "    sample: a list of numbers\n",
    "    mu_0: The value of the null hyothesis for population mean\n",
    "    \n",
    "    \"\"\"    \n",
    "    # sample mean\n",
    "    \n",
    "\n",
    "    # sample standard deviation with n-1 in the denominator\n",
    "    \n",
    "    \n",
    "    # number of measurements (length of sample list)\n",
    "    \n",
    "    \n",
    "    # degree of freedom\n",
    "    \n",
    "\n",
    "    # t-value for sample mean distribution (using standard error)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # calculate the cummulative probability of landing\n",
    "    # on or below this t-value\n",
    "\n",
    "    \n",
    "    # return three values\n",
    "    return t,p,nu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Low Sample\n",
    "\n",
    "Let's consider our first batch of 10 measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = [487, 495, 482, 474, 489, 499, 492, 485, 483, 497]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost all of our measurments are less than 500, so intuitively we know that it is unlikely to get 10 measurements in a row that are less than the mean.  Still we want to quantify our results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will calculate the cummulative probabilty of landing on or below this z-value.\n",
    "\n",
    "We can catch and unpack the three variables using the same comma separated syntax we used to return values from the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t,p,nu = left_tailed_t_test(sample,500)\n",
    "print(\"The t-value is: {}\".format(t))\n",
    "print(\"The p-value is: {}\".format(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a pretty low probability.  Therefor we can reject the null hypthesis in favor of the alternative hypthesis, that $\\mu < 500g$.  Basically what we have said here is that if the population mean is 500 then there is a ~0.04\\% chance that we would have pulled a sample of 10 measurements with those values.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the cummulative probability using our function above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcdf_plot_left(t,nu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cummulative probability is not even visible.\n",
    "\n",
    "#### High Sample\n",
    "\n",
    "Now let's look and see what happens when we have a sample which is above the value of our null hypthesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = [504, 510, 502, 495, 513, 527, 503, 504, 519, 521]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost all of our measurments are greater than 500, so intuitively we know that it is unlikely to get 10 measurements in a row that are greater than the mean.  However, our alternative hypothesis is that the mean is below 500 so we are integrating from the left.  While a streak above 500 might cause us to hesitate about our null hypothesis, it certainly doesn't support the alternative.  And the left tailed t-test only tests for values below.  \n",
    "\n",
    "Now we will calculate the cummulative probabilty of landing on or below this t-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t,p,nu = left_tailed_t_test(sample,500)\n",
    "print(\"The t-value is: {}\".format(t))\n",
    "print(\"The p-value is: {}\".format(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the cummulative probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcdf_plot_left(t,nu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to point out that because we only did a one-tailed test, we are not concluding that the null hypothesis is true.  Simply that we can't reject it in favor of the alternative hypothesis that the population mean is below 500.  This is why choosing a correct null and alternative hypothesis is so important.\n",
    "\n",
    "#### Ambiguous Sample #1\n",
    "\n",
    "Now let's look at some more ambiguous samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = [504, 495, 483, 495, 513, 492, 503, 504, 472, 521]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case it is not as obvious because we have some vales above and below the null hypothesis.  Let's run the same test and see what our p-value is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t,p,nu = left_tailed_t_test(sample,500)\n",
    "print(\"The t-value is: {}\".format(t))\n",
    "print(\"The p-value is: {}\".format(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the cummulative probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcdf_plot_left(t,nu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This p-value indicates that there is a 34.8% chance of getting this particular sample if the null hypothesis is true.  If our level of significance is 5% then we cannot reject the null hypthesis in favor of the alternative hypothesis.\n",
    "\n",
    "#### Ambiguous Sample #2\n",
    "\n",
    "Let's look at a sample with a few more \"high\" values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = [513, 495, 503, 482, 519, 474, 501, 499, 504, 521]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will calculate the cummulative probabilty of landing on or below this z-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t,p,nu = left_tailed_t_test(sample,500)\n",
    "print(\"The t-value is: {}\".format(t))\n",
    "print(\"The p-value is: {}\".format(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the p-value is saying that there is a 58.9% chance that we got this particular sample assuming that the null hypthesis is true, so we cannot reject it.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the cummulative probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcdf_plot_left(t,nu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Right Tailed t-test\n",
    "\n",
    "Some of our previous results were not particularly useful.  It was obvious that the population mean was probably not equal to 500 because all our samples were above that.  Yet we got really high p-values!  Isn't the p-value the probability that we got a particular sample if the null hyptothesis is true?  Sort of... The alternative hypothesis controls how we set up the test, so high p-values really have no meaning.  Only low p-values allow us to make any sort of conclusion.  And even then we aren't proving anything, just infering that one assumption is likely false and it's probably false in a particular way.\n",
    "\n",
    "So how do me test to see if population mean is likely to be above a certain value?  We use a right tailed t-test which just means that we calculate the cumulative probability above our calculated t-statistic.  Which is just one minus the cumulative probability below our t-statistic.\n",
    "\n",
    "Suppose we work for a chemical company on the filling process.  We are testing some new equipment so we don't have a great estimate for the mean or standard deviation. Our goal is to get 500 grams of chemical into each container.   We take 10 measurements and we would like to know if our population mean is less than 500 grams.\n",
    "\n",
    "First we set up our null hypthesis.\n",
    "$$\\Large H_0: \\mu=500g$$\n",
    "\n",
    "The null hypothesis is the default assumption.  We use this to construct our hypothestical distribution.  If our data contradicts this assumption then we reject this default hypthesis in favor of the alternative hypothesis.  In this case the alternative hypothesis is:\n",
    "\n",
    "$$ \\Large H_a: \\mu > 500g$$\n",
    "\n",
    "Now that we have our null and alternative hypothesis, we can follow some basic steps to test and see if it is likely that our null hypothesis is correct.\n",
    "\n",
    "1. Calculate sample mean\n",
    "2. Calculate t-value using the sample mean, the standard error of the mean (using sample standard deviation), and the population mean proposed by the null hypthesis.\n",
    "3. Calculate the cumulative probability above that t-value.  This will tell us the likelihood of getting a result at least as extreme as our sample if the null hypthesis was true.\n",
    "4. Compare this cumulative probability to our required level of significance.\n",
    "\n",
    "Basically, the p-value is going to tell us how likely it is that we got that particular sample if the null hypothesis is true.\n",
    "\n",
    "For the t-statistic in step (2), we use the form which describes the sample distirbution.\n",
    "\n",
    "$$\\Large t = \\frac{\\bar{x} - \\mu}{\\frac{s}{\\sqrt{n}}}$$\n",
    "\n",
    "We'll use the same samples as before so we can see that we get the opposite results (except in the last case).\n",
    "\n",
    "Before we get into the testing though let's build another function to visualize the p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tcdf_plot_right(t,nu):\n",
    "    \"\"\"This function visualizes the cumulative \n",
    "    probability of the t-distribution above a defined\n",
    "    t-value.  This is the p-value that will allow us\n",
    "    to make an inference (or not).\"\"\"\n",
    "        \n",
    "    # make the figure \n",
    "    plt.figure(figsize=(10,6))\n",
    "\n",
    "    # outcome space\n",
    "    x = np.linspace(-5,5,num=101)\n",
    "\n",
    "    # probability distribution\n",
    "    f = st.t.pdf(x,nu)\n",
    "    plt.plot(x,f)\n",
    "    \n",
    "    # shade the curve\n",
    "    plt.fill_between(x,f,color=\"C0\",alpha=0.2)\n",
    "\n",
    "    # fill in cummulative region\n",
    "    x_sub = np.linspace(t,5,num=101)\n",
    "    f_sub = st.t.pdf(x_sub,nu)\n",
    "    plt.fill_between(x_sub,f_sub,color=\"red\")\n",
    "\n",
    "    # format plot\n",
    "    plt.xlabel(\"Outcome\",fontsize=18)\n",
    "    plt.ylim(0,1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use our function to gain some intution about how the t-statistic impacts p-value.  In this case we are testing for values above the assumed population mean in the null hypothesis.  The p-value is the cumulative probability shown in red.  Test several values of `t`.  Looking at the t-statistic above, what could happpen to make `t` higher or lower?  Keep in mind that $\\mu$ will be a constant because we have made an assumption about it's value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 2\n",
    "nu = 5\n",
    "\n",
    "tcdf_plot_right(t,nu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's build a function to do the right tailed t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def right_tailed_t_test(sample,mu_0):\n",
    "    \"\"\"\n",
    "    This function calculates a p-value using a \n",
    "    right-tailed t-test for the population mean.  \n",
    "    \n",
    "    It takes two values as input.\n",
    "    \n",
    "    sample: a list of numbers\n",
    "    mu_0: The value of the null hyothesis for population mean\n",
    "    \"\"\" \n",
    "    # sample mean\n",
    "    \n",
    "\n",
    "    # sample standard deviation\n",
    "    \n",
    "    \n",
    "    # number of measurments in sample (length of sample list)\n",
    "    \n",
    "    \n",
    "    # degree of freedom\n",
    "    \n",
    "\n",
    "    # t-value for sample mean distribution (using standard error)\n",
    "\n",
    "    \n",
    "    # calculate the cummulative probability of landing\n",
    "    # on or above this t-value (1 - P(on or below))\n",
    "\n",
    "    \n",
    "    return t,p,nu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Low Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = [487, 495, 482, 474, 489, 499, 492, 485, 483, 497]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost all of our measurments are less than 500, so intuitively we know that it is unlikely to get 10 measurements in a row that are less than the mean.  But since our alternative hypothesis for a right-tailed test is that the population mean is greater than the null value, we aren'y likely to get useful inference here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will calculate the cummulative probabilty of landing on or above this t-value.  We do this by calculating the cumulative probability on the high side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t,p,nu = right_tailed_t_test(sample,500)\n",
    "print(\"The t-value is: {}\".format(t))\n",
    "print(\"The p-value is: {}\".format(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an extrememly high probability so we cannot reject the null hypthesis in favor of the alternative hypthesis.  This does not prove the null hypothesis.  We can look at the data and see that it is unlikely to be correct, but we only tested for values greater than the null value.\n",
    "\n",
    "Let's look at the p-value on the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcdf_plot_right(t,nu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### High Sample\n",
    "\n",
    "Now let's look and see what happens when we have a sample which is above the value of our null hypthesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = [504, 510, 502, 495, 513, 527, 503, 504, 519, 521]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost all of our measurments are greater than 500, so intuitively we know that it is unlikely to get 10 measurements in a row that are greater than the mean.  \n",
    "\n",
    "Now we will calculate the cummulative probabilty of landing on or above this t-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t,p,nu = right_tailed_t_test(sample,500)\n",
    "print(\"The t-value is: {}\".format(t))\n",
    "print(\"The p-value is: {}\".format(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a pretty low probability so we can reject $H_0$ in favor of $H_a$, that the mean is greater than 500g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcdf_plot_right(t,nu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ambiguous Sample #1\n",
    "\n",
    "Now let's look at some more ambiguous samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = [487, 495, 503, 482, 519, 474, 489, 499, 504, 521]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case it is not as obvious because we have some values above and below the null hypothesis.  Let's run the same test and see what our p-value is.\n",
    "\n",
    "Now we will calculate the cummulative probabilty of landing on or above this t-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t,p,nu = right_tailed_t_test(sample,500)\n",
    "print(\"The t-value is: {}\".format(t))\n",
    "print(\"The p-value is: {}\".format(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This p-value indicates that there is a 70.6% chance of getting this particular sample if the null hypothesis is true. We cannot reject the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcdf_plot_right(t,nu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ambiguous Sample #2\n",
    "\n",
    "Let's look at a sample with a few more \"high\" values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = [513, 495, 503, 482, 519, 474, 501, 499, 504, 521]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will calculate the cummulative probabilty of landing on or above this z-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t,p,nu = right_tailed_t_test(sample,500)\n",
    "print(\"The t-value is: {}\".format(t))\n",
    "print(\"The p-value is: {}\".format(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the p-value is saying that there is a ~41% chance that we got this particular sample assuming that the null hypthesis is true, so we cannot reject it.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcdf_plot_right(t,nu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis Testing in the Wild!\n",
    "\n",
    "It's all fun and games to make up samples full of measurements that give us interesting (or purposefully uninteresting) conclusions.  But what happens when we apply this stuff to actual data?  Let's go back to the penguins to find out.  \n",
    "\n",
    "You should have code in previous studios (Week 03) that will let you load the penquin data set, isolate species, calculate summaray statistics, and grab a single sample of 5 measurements.  \n",
    "\n",
    "For each species choose a factor and set up both a left tailed and right tailed test using a sample of 5 measurements.  Use your summary stats to guide you in setting up your null and alternative hypothesis.  Now repeat this process several times paying careful attention to how your p-value changes.  If you are only getting high (bad!) p-values, consider adjusting your null and alternative hypothesis.  Also if all of your p-values are staggeringly low, consider finding the edge, where a few are above 0.05 and a few are below.  The try this for many samples and gain some intution about how the sample influences the outcome.  If we assume the mean of the whole data set is an accurate representation of the population, how likely are we to make the right conclusion if we only have one sample of 5 measurements?\n",
    "\n",
    "The pro-move here is to loop around it once you get it working and make a histogram to understand the behavior at a high level.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
