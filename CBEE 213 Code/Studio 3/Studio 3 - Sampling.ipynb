{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Samples!\n",
    "\n",
    "When you first saw the heading you might have thought I was talking about the Boulder, Colorado rock band (not so) notably featured in the 2011 documentary *The Best Band You've Never Heard Of*, but that's not what we're doing here.  But if you're looking for a few feels I highly recommend that at some point you head over to your favorite streaming service (after class obviously) and check out *Could It Be Another Change?*  So melodic, much harmony.  #sappylovesong\n",
    "\n",
    "What does this have to do with data analysis?  I'm so glad you asked!\n",
    "\n",
    "We've spent some time talking about uncertainty and looking at probability distributions, but probability distributions apply to the entire *population*.  The population is the total amount of instances, devices, people, etc. that we might want to measure.  For example, if I want to know the average typing speed of students at Oregon State University I would need to measure the typing speed of every single student at OSU and there's over 29,000!  No way am I putting in that kind of effort.  So what do we do?  We take a *sample*, a subset of measurements or observations that we decide will be representative of the total population.  \n",
    "\n",
    "The problem is that, due to the uncertainty in our population, we have uncertainty in our sample?  How do I know that my sample is representative and accurately predicts population data?  How can I predict how wrong my sample might be?  These questions form the foundation of statistical analysis.  While it's nice to make cool plots and do lots of summary stats, what I need to know most is what to do when I only have a few data points.  \n",
    "\n",
    "In order to know what to do the first thing I have to understand is how samples behave relative to the population. Upon this understanding we can build the tools which will help us understand all the ways in which we might be wrong.  \n",
    "\n",
    "So today we will sample some data and do statistics on the samples and make plots about the samples and we will see how the samples relate to the population.  How sometimes the samples are good, and sometimes the samples are not good, and sometimes they're weird in ways that make them seem good at first but in the end they are not good.  \n",
    "\n",
    "Thank you for coming to my Ted Talk.  Let's import some libraries and get after it!  We'll talk about each of the libraries as we use them.  For now I'm just going to import them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Random Population Data for Testing\n",
    "\n",
    "The first thing we want to do is get some population data to sample from.  Sometimes it's nice to just make some fake data to practice with.  We can do this using the Numpy library.  `numpy.random` has several functions for generating different kinds of randomly distributed data.  These are genrally called *random number generators*.  They are very useful for building simulations of [stochastic processes](https://en.wikipedia.org/wiki/Stochastic_process).  This library can generate random numbers following a variety of distributions.  \n",
    "\n",
    "The following code will generate and array of 10 random numbers and assign the array to a variable named *population*.  The function `randn()` will generate values from a normal distribution with $\\mu=0$ (mean) and $\\sigma=1$ (std dev).\n",
    "\n",
    "```Python\n",
    "population = np.random.randn(10)\n",
    "```\n",
    "\n",
    "Go ahead and make your data in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a look at the data using the `print()` function.  After you have it printed, go ahead and run the previous cell a few times, and print the data below each time so you can see that the values are changing.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course looking at a string of numbers doesn't really tell us anything.  Let try some visualization.  The best way to visualize single factor continuous data is to make a histogram.  We'll just use the histogram function included with matplotlib since we aren't dealing with a Pandas DataFrame.\n",
    "\n",
    "```Python\n",
    "plt.hist(population)\n",
    "plt.xlim(-5,5)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "The command `plt.xlim()` sets the axis limits on the x-axis.  This is going to be useful as we create further histograms.  By default matplotlib will scale the axis to the range of data.  If we fix the axis we can get a better visualization of the changes.\n",
    "\n",
    "We don't *have* to include the `plt.show()`, but if we don't it will print some extra stuff to the output below.  An array of bin counts, and another of bin edges and also a list of *patches* that the plotting tool used to make the nice colored bits.  But `plt.show()` will suppress that so we don't have to look at it.  You can delete it and see what happens.  It won't break anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a pretty boring histogram.  Just a few random collumns and it's hard to really tell what's going on.  That's because there's only 10 data points in our whole population.  We want a much bigger population.  Try changing the number of data points to 100 and run everything above this cell again.  Notice how the histogram changes.  Discuss this shape with your group. \n",
    "\n",
    "Each bar is called a *bin* and we can think of it like a bucket holding all of the data points within that range.  \n",
    "\n",
    "Now let's start to refine our histogram.  First we will increase the number of data points to 1,000.  Then we will increase the number of bins in our histgram by adding a `bins=25` option to our histogram.\n",
    "\n",
    "```Python\n",
    "plt.hist(population,bins=25)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "Increase the number of points as well as the number of bins.  Experiment with them until you have an intuitive feel for the result.  What happens if the number of bins get's larger while the population size stays the same?  What happens if the population size increases while the number of bins stays the same?  Remember you can use SHIFT+ENTER to run a single cell.\n",
    "\n",
    "In the end, let's settle on 10,000 data points in our population, and 50 bins in our histogram.  This should give a decent bell curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Sampling\n",
    "\n",
    "Now that we have our population, the next step is to figure out how to take a sample.  The strategy we will emply here is to generate random index variables and use them to pull values from the population array. \n",
    "\n",
    "The function `np.random.reandint()` will generate random positive integers.  Since we use integers to index the arrays we can just use it to generate random index values.  It takes two arguments.  The first is the highest possible integer. The second is the keyword argument *size* which tells us how many integers we want.  So if we set `size=5` then we will get 5 integers.  We'll go ahead an automate this to scale with the size of the population by setting the max value to the length of the population array.\n",
    "\n",
    "```Python\n",
    "# get largest index of population array\n",
    "max_idx=len(population)\n",
    "\n",
    "# define number of measurements in the sample\n",
    "n=5\n",
    "\n",
    "# get random index values\n",
    "idx = np.random.randint(max_idx,size=n)\n",
    "print(idx)\n",
    "\n",
    "# get sample\n",
    "sample = population[idx]\n",
    "print(sample)\n",
    "```\n",
    "\n",
    "Run this cell a few times to see how the values change.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to start to looks at the summary statistics of the sample.  Edit the cell above to also calculate the mean and standard deviation of the sample.  Don't forget to include some well-formatted output so we can read the output.\n",
    "\n",
    "```Python\n",
    "# calculate x_bar\n",
    "x_bar = np.mean(sample)\n",
    "print(\"x-bar: {}\".format(x_bar))\n",
    "```\n",
    "\n",
    "You can use `np.std()` to calculate the standard deviation.\n",
    "\n",
    "Now run that cell several times and pay attention to how the mean changes.  Remember that our population has a mean of 0 and a standard deviation of 1.  How often does the sample of 5 measurements accurately reflect the population?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeated Sampling\n",
    "\n",
    "Just as we need many data points to describe a population, it's useful to have many samples to understand how the sample means are distributed.  Let's build a short for-loop to take many samples and save all the sample means.  \n",
    "\n",
    "```Python\n",
    "# intialize list of sample means\n",
    "x_bar=[]\n",
    "\n",
    "# number of measurements per sample\n",
    "n = 25\n",
    "\n",
    "# loop to pull samples and calculate averages\n",
    "for i in range(100):\n",
    "    \n",
    "    # get random index values\n",
    "    idx = np.random.randint(len(population),size=n)\n",
    "    \n",
    "    # get sample\n",
    "    sample = population[idx]\n",
    "    \n",
    "    # save sample mean in x_bar\n",
    "    x_bar.append(np.mean(sample))\n",
    "```\n",
    "\n",
    "When you get the loop working you can make a histogram out of `x_bar`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the spread of the sample mean histogram compare to the spread of the population?  Increase the number of samples to 1000 (number of times the loop runs, not the number of measurements in a sample).  What does the histogram look like?\n",
    "\n",
    "Now increase the number of measurements per sample from 5 to 10.  How does the spread of this histogram change?  What if we go to 25?  Or 50?  \n",
    "\n",
    "The spread of the sample mean distribution is called the *standard error or the mean* and it depends on both the standard deviation of the population and also the number of measurements in a sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Central Limit Theorem\n",
    "\n",
    "In the previous example we were sampling from a population that was normally distributed so it makes sense that our sample mean distribution would also be normally distributed.  But what happens if our population is not normally distributed?\n",
    "\n",
    "This code will generate a skewed distribution.\n",
    "\n",
    "```Python\n",
    "population = np.random.gamma(2,2,10000)\n",
    "```\n",
    "\n",
    "Repeat the analysis above for this population.  Generate a histogram of the population.  Then take some individual samples and see how they behave.  Finally loop through and take samples of 5 measurements and plot the sample mean distribution.  Now increase the number of measurements per sample and repeat.  Then increase again.  How many measurements do you need to get a nice normal distribution?\n",
    "\n",
    "Also calculate the population average.  How does this compare with the sample average distribution?\n",
    "\n",
    "Add as many cells as you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real Data!\n",
    "\n",
    "So this is neat and all, but you're probably wondering how it all works out if we actually use some real data.  Let's use our penguin data set since we're already comfortable with it.\n",
    "\n",
    "Read the data into a pandas DataFrame.  Use your notebook from last week as reference. Go ahead and run the `df.head()` function just to orient yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets figure out how to take one sample from the data.  Fortunately this is built right into pandas!  It's almost like the developers thought about doing stats...\n",
    "\n",
    "Let's say we want a sample of 5 data points from the *culmen_length_mm* column.  This code will pull the sample.  Run it a few times to see the sample change.  Note the index and values.\n",
    "\n",
    "```Python\n",
    "df[\"culmen_length_mm\"].sample(n=5)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `.mean()` function on the sample just like we could on the groupby().  \n",
    "\n",
    "```Python\n",
    "df[\"culmen_length_mm\"].sample(n=5).mean()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now calculate the sample standard deviation.  Again use your notebook from week 2 as reference.  \n",
    "\n",
    "*(Note:  In both of these cases the sample changes every time we run the cell.  We will learn in just a few cells how to pull one sample and calculate both statistics)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we only want to work with the data from one species.  We learned last week how to isolate species data using a boolean index.  Pandas uses *hierarchical indexing*, so we can pull values using a boolean index and then get values from a column like this.  Try it below.\n",
    "\n",
    "```Python\n",
    "Adelie_idx = df[\"species\"] == \"Adelie\"\n",
    "df[Adelie_idx][\"culmen_length_mm\"].sample(n=5).mean()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now write code to pull samples from the other two species and calculate the mean.  How do the sample means compare?  What about flipper length?  Write a few lines of code to find out.  Run it several times to get some intutition about the variability in the samples.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the value coming out of the `df.sample().mean()` function is a single float value.  This is exactly the same as the value we produced above when taking the average of our numpy sample.  Implement the same for-loop used above to save an array of sample mean distributions for each species of penguin and create the histogram for each one.  How are they different?  What is a good range for the axis limits on these plots?  How do they change if we increase the number of samples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try sampling some of the other columns of data.  What do the sample mean histograms look like?  How do they compare to the plots generated during exploratory data analysis last week?  Create as many additional cells as needed, but you must thoroughly explore at least on other column of data before you can leave early."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
